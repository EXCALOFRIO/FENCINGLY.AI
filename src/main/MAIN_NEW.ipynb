{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6174e572-f972-4ebd-8f00-6155f16cf2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VER GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU disponible\")\n",
    "else:\n",
    "    print(\"GPU no disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7fd6d-67e4-4ef0-8e39-50baa0f34d98",
   "metadata": {},
   "source": [
    "# IMPORTAR JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 7694/7694 [00:19<00:00, 392.65it/s]\n",
      "Loading data: 100%|██████████| 7694/7694 [00:20<00:00, 369.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from custom_transforms import *\n",
    "from dataset import *\n",
    "from generarModelo import *\n",
    "\n",
    "\n",
    "izquierda_dir = r\"C:/Users/Alejandro/TFG_ENTRENAMIENTO/JSON_FORMADOS/IZQUIERDA_NORMALIZADO\"\n",
    "derecha_dir = r\"C:/Users/Alejandro/TFG_ENTRENAMIENTO/JSON_FORMADOS/DERECHA_NORMALIZADO\"\n",
    "\n",
    "porcentaje_entrenamiento = 0.70\n",
    "porcentaje_validacion = 0.15\n",
    "porcentaje_prueba = 0.15\n",
    "\n",
    "datos_entrenamiento, datos_validacion, datos_prueba, etiquetas_entrenamiento, etiquetas_validacion, etiquetas_prueba = cargar_y_preparar_datos(izquierda_dir, derecha_dir, porcentaje_entrenamiento, porcentaje_validacion, porcentaje_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe107701-b087-4e5b-86d0-00653022fa2a",
   "metadata": {},
   "source": [
    "# TRANSFORMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15486db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar transformacion TAMAÑO\n",
    "datos_entrenamiento_transformados_zoom = transformacion_zoom(datos_entrenamiento)\n",
    "etiquetas_entrenamiento_transformados_zoom = etiquetas_entrenamiento\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE X\n",
    "datos_entrenamiento_transformados_translacionX = desplazar_posesX(datos_entrenamiento)\n",
    "etiquetas_entrenamiento_transformados_translacionX = etiquetas_entrenamiento\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE Y\n",
    "datos_entrenamiento_transformados_translacionY = desplazar_posesY(datos_entrenamiento)\n",
    "etiquetas_entrenamiento_transformados_translacionY = etiquetas_entrenamiento\n",
    "\n",
    "#Generar transformacion FLIP\n",
    "datos_entrenamiento_transformados_flip = flip_poses(datos_entrenamiento)\n",
    "etiquetas_entrenamiento_transformados_flip = invertir_etiquetas(etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d632fb74-3c3f-4785-9ae4-0bafa59fbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar transformacion TAMAÑO\n",
    "datos_validacion_transformados_zoom = transformacion_zoom(datos_validacion)\n",
    "etiquetas_validacion_transformados_zoom = etiquetas_validacion\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE X\n",
    "datos_validacion_transformados_translacionX = desplazar_posesX(datos_validacion)\n",
    "etiquetas_validacion_transformados_translacionX = etiquetas_validacion\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE Y\n",
    "datos_validacion_transformados_translacionY = desplazar_posesY(datos_validacion)\n",
    "etiquetas_validacion_transformados_translacionY = etiquetas_validacion\n",
    "\n",
    "#Generar transformacion FLIP\n",
    "datos_validacion_transformados_flip = flip_poses(datos_validacion)\n",
    "etiquetas_validacion_transformados_flip = invertir_etiquetas(etiquetas_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f879d4bb-08e8-4e8d-ac56-54fcf55f1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar transformacion TAMAÑO\n",
    "datos_prueba_transformados_zoom = transformacion_zoom(datos_prueba)\n",
    "etiquetas_prueba_transformados_zoom = etiquetas_prueba\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE X\n",
    "datos_prueba_transformados_translacionX = desplazar_posesX(datos_prueba)\n",
    "etiquetas_prueba_transformados_translacionX = etiquetas_prueba\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE Y\n",
    "datos_prueba_transformados_translacionY = desplazar_posesY(datos_prueba)\n",
    "etiquetas_prueba_transformados_translacionY = etiquetas_prueba\n",
    "\n",
    "#Generar transformacion FLIP\n",
    "datos_prueba_transformados_flip = flip_poses(datos_prueba)\n",
    "etiquetas_prueba_transformados_flip = invertir_etiquetas(etiquetas_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c4e72-9ee4-4bea-b34c-56eae9a54b70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# COMPARAR ANTES Y DESPUÉS TRANSFORMACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0805bb-5030-4827-aac6-c8e56a1277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZOOM\n",
    "transformacion_dato(datos_entrenamiento, etiquetas_entrenamiento, datos_entrenamiento_transformados_zoom, etiquetas_entrenamiento_transformados_zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSLACION X\n",
    "transformacion_dato(datos_entrenamiento, etiquetas_entrenamiento, datos_entrenamiento_transformados_translacionX, etiquetas_entrenamiento_transformados_translacionX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSLACION Y\n",
    "transformacion_dato(datos_entrenamiento, etiquetas_entrenamiento, datos_entrenamiento_transformados_translacionY, etiquetas_entrenamiento_transformados_translacionY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018737a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIP\n",
    "transformacion_dato(datos_entrenamiento, etiquetas_entrenamiento, datos_entrenamiento_transformados_flip, etiquetas_entrenamiento_transformados_flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddeedd-1662-44af-8e5a-fd8efbd07071",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VER TENSORES TRANSFORMADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad8d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[1]), gif(datos_entrenamiento_transformados_zoom[1]), \"resultado.gif\")\n",
    "\n",
    "Image(\"resultado.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[2]), gif(datos_entrenamiento_transformados_translacionX[2]), \"resultado.gif\")\n",
    "\n",
    "Image(\"resultado.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[2]), gif(datos_entrenamiento_transformados_translacionY[2]), \"resultado.gif\")\n",
    "\n",
    "Image(\"resultado.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import *\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[2]), gif(datos_entrenamiento_transformados_flip[2]), \"resultado.gif\")\n",
    "\n",
    "Image(\"resultado.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e45a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(gif(datos_entrenamiento_transformados_flip[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos_entrenamiento.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2178ef-aba3-4dff-87a2-36618050d04c",
   "metadata": {},
   "source": [
    "# VER LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5595a92e-0e20-4e01-be23-867d58c3cee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2769b68e42bc8fcb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2769b68e42bc8fcb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 64569;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fino --port 64569"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc67fc-2518-43fd-8be5-5ec87d6afc82",
   "metadata": {},
   "source": [
    "# ENTRENAR OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe3f65-cedb-4ef8-bcfb-219bd3c1e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = preparar_entrenamiento(datos_entrenamiento, etiquetas_entrenamiento, datos_validacion, etiquetas_validacion, 64)\n",
    "# Entrenamiento con Optuna y guardado de logs\n",
    "study = entrenar_con_optuna(train_loader, val_loader, n_trials=5, num_epochs=50, patience=5)\n",
    "log_dir = \"./logs/logsOptuna\"\n",
    "guardar_logs(study, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ee201-5c58-4869-a110-eedccb30dcc5",
   "metadata": {},
   "source": [
    "# ENTRENAR FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b52c8-b2b1-4c4d-9995-66c1e7dabbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los datos de entrenamiento y validación\n",
    "datos_entrenamiento_final = torch.cat((datos_entrenamiento, datos_validacion), dim=0)\n",
    "etiquetas_entrenamiento_final = torch.cat((etiquetas_entrenamiento, etiquetas_validacion), dim=0)\n",
    "\n",
    "# Preparar los dataloaders con los datos combinados\n",
    "train_loader, val_loader = preparar_entrenamiento(datos_entrenamiento_final, etiquetas_entrenamiento_final, datos_prueba, etiquetas_prueba, 64)\n",
    "\n",
    "# Entrenamiento del modelo con los mejores parámetros\n",
    "best_params = study.best_trial.params\n",
    "best_params_local = {'learning_rate': 8.492389446863165e-06, 'lstm_units': 1226, 'dense_units': 1094, 'dropout_rate': 0.2860955821910263}\n",
    "modelo_final = entrenar_modelo(train_loader, val_loader, best_params_local, num_epochs=200)\n",
    "log_dir = \"./logs/logsFino\"\n",
    "guardar_logs(study, log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030f013-7b7f-409e-8880-94475748cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAR DATASET CON TRANSFORMACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb72e0c-b37d-4a32-999c-6e32b78dbb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO INICIAL 10770\n",
      "VALIDACION INICIAL 2308\n",
      "PRUEBA INICIAL 2310\n",
      "ENTRENAMIENTO INICIAL 53850\n",
      "VALIDACION INICIAL 11540\n",
      "PRUEBA INICIAL 11550\n"
     ]
    }
   ],
   "source": [
    "print('ENTRENAMIENTO INICIAL',datos_entrenamiento.shape[0])\n",
    "print('VALIDACION INICIAL',datos_validacion.shape[0])\n",
    "print('PRUEBA INICIAL',datos_prueba.shape[0])\n",
    "# Creamos un conjunto de datos combinado\n",
    "datos_entrenamiento_total = torch.cat((\n",
    "    datos_entrenamiento,\n",
    "    datos_entrenamiento_transformados_zoom,\n",
    "    datos_entrenamiento_transformados_translacionX,\n",
    "    datos_entrenamiento_transformados_translacionY,\n",
    "    datos_entrenamiento_transformados_flip), dim=0)\n",
    "\n",
    "# Creamos un conjunto de etiquetas combinado\n",
    "etiquetas_entrenamiento_total = torch.cat((\n",
    "    etiquetas_entrenamiento,\n",
    "    etiquetas_entrenamiento_transformados_zoom,\n",
    "    etiquetas_entrenamiento_transformados_translacionX,\n",
    "    etiquetas_entrenamiento_transformados_translacionY,\n",
    "    etiquetas_entrenamiento_transformados_flip), dim=0)\n",
    "\n",
    "# Creamos un conjunto de datos combinado\n",
    "datos_validacion_total = torch.cat((\n",
    "    datos_validacion,\n",
    "    datos_validacion_transformados_zoom,\n",
    "    datos_validacion_transformados_translacionX,\n",
    "    datos_validacion_transformados_translacionY,\n",
    "    datos_validacion_transformados_flip), dim=0)\n",
    "\n",
    "# Creamos un conjunto de etiquetas combinado\n",
    "etiquetas_validacion_total = torch.cat((\n",
    "    etiquetas_validacion,\n",
    "    etiquetas_validacion_transformados_zoom,\n",
    "    etiquetas_validacion_transformados_translacionX,\n",
    "    etiquetas_validacion_transformados_translacionY,\n",
    "    etiquetas_validacion_transformados_flip), dim=0)\n",
    "\n",
    "# Creamos un conjunto de datos combinado\n",
    "datos_prueba_total = torch.cat((\n",
    "    datos_prueba,\n",
    "    datos_prueba_transformados_zoom,\n",
    "    datos_prueba_transformados_translacionX,\n",
    "    datos_prueba_transformados_translacionY,\n",
    "    datos_prueba_transformados_flip), dim=0)\n",
    "\n",
    "# Creamos un conjunto de etiquetas combinado\n",
    "etiquetas_prueba_total = torch.cat((\n",
    "    etiquetas_prueba,\n",
    "    etiquetas_prueba_transformados_zoom,\n",
    "    etiquetas_prueba_transformados_translacionX,\n",
    "    etiquetas_prueba_transformados_translacionY,\n",
    "    etiquetas_prueba_transformados_flip), dim=0)\n",
    "\n",
    "print('ENTRENAMIENTO INICIAL',datos_entrenamiento_total.shape[0])\n",
    "print('VALIDACION INICIAL',datos_validacion_total.shape[0])\n",
    "print('PRUEBA INICIAL',datos_prueba_total.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e34a38-5902-4dff-b6fb-0b6c7f66ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Training:  24%|██▍       | 49/200 [35:08<1:46:51, 42.46s/epoch]"
     ]
    }
   ],
   "source": [
    "# Concatenar los datos de entrenamiento y validación\n",
    "datos_entrenamiento_final_total = torch.cat((datos_entrenamiento_total, datos_validacion_total), dim=0)\n",
    "etiquetas_entrenamiento_final_total = torch.cat((etiquetas_entrenamiento_total, etiquetas_validacion_total), dim=0)\n",
    "\n",
    "# Preparar los dataloaders con los datos combinados\n",
    "train_loader, val_loader = preparar_entrenamiento(datos_entrenamiento_final_total, etiquetas_entrenamiento_final_total, datos_prueba_total, etiquetas_prueba_total, 64)\n",
    "\n",
    "# Entrenamiento del modelo con los mejores parámetros\n",
    "#best_params = study.best_trial.params\n",
    "best_params_local = {'learning_rate': 8.492389446863165e-06, 'lstm_units': 1226, 'dense_units': 1094, 'dropout_rate': 0.2860955821910263}\n",
    "modelo_final = entrenar_modelo(train_loader, val_loader, best_params_local, num_epochs=200)\n",
    "log_dir = \"./logs/fino_transform\"\n",
    "guardar_logs(study, log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09191772-c3ef-4715-8161-6325d9355ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
