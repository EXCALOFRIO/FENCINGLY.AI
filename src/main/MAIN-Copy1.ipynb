{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6174e572-f972-4ebd-8f00-6155f16cf2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VER GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU disponible\")\n",
    "else:\n",
    "    print(\"GPU no disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7fd6d-67e4-4ef0-8e39-50baa0f34d98",
   "metadata": {},
   "source": [
    "# IMPORTAR JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 105/105 [00:00<00:00, 277.96it/s]\n",
      "Loading data: 100%|██████████| 105/105 [00:00<00:00, 275.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from custom_transforms import *\n",
    "from dataset import *\n",
    "from generarModelo import *\n",
    "from torch.nn.functional import normalize\n",
    "from validar_transformaciones import *\n",
    "\n",
    "\n",
    "izquierda_dir = r\"C:/Users/Alejandro/TFG_ENTRENAMIENTO/JSON_FORMADOS/IZQUIERDA_NORMALIZADO - copia\"\n",
    "derecha_dir = r\"C:/Users/Alejandro/TFG_ENTRENAMIENTO/JSON_FORMADOS/DERECHA_NORMALIZADO - copia\"\n",
    "\n",
    "porcentaje_entrenamiento = 0.70\n",
    "porcentaje_validacion = 0.15\n",
    "porcentaje_prueba = 0.15\n",
    "\n",
    "datos_entrenamiento, datos_validacion, datos_prueba, etiquetas_entrenamiento, etiquetas_validacion, etiquetas_prueba = cargar_y_preparar_datos(izquierda_dir, derecha_dir, porcentaje_entrenamiento, porcentaje_validacion, porcentaje_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe107701-b087-4e5b-86d0-00653022fa2a",
   "metadata": {},
   "source": [
    "# TRANSFORMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724e8ba-a407-4437-906d-29168565fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos_entrenamiento[7]-datos_entrenamiento_transformados_zoom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e641d-80b5-4ad1-a4d8-e24863c4464d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15486db",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento_trans, etiquetas_entrenamiento_trans = aplicar_transformaciones_n_veces(datos_entrenamiento, etiquetas_entrenamiento, 5)\n",
    "datos_validacion_trans, etiquetas_validacion_trans = aplicar_transformaciones_n_veces(datos_validacion, etiquetas_validacion, 5)\n",
    "datos_prueba_trans, etiquetas_prueba_trans = aplicar_transformaciones_n_veces(datos_prueba, etiquetas_prueba, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c4e72-9ee4-4bea-b34c-56eae9a54b70",
   "metadata": {},
   "source": [
    "# COMPARAR ANTES Y DESPUÉS TRANSFORMACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf75221-4130-4bac-b322-94b02a32460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar transformacion TAMAÑO\n",
    "datos_entrenamiento_transformados_zoom = transformacion_zoom(datos_entrenamiento[38],etiquetas_entrenamiento[38])[0]\n",
    "etiquetas_entrenamiento_transformados_zoom = etiquetas_entrenamiento\n",
    "\n",
    "#Generar transformacion TRANSLACION EJE X\n",
    "datos_entrenamiento_transformados_translacionX = desplazar_posesX(datos_entrenamiento[5],etiquetas_entrenamiento[5])[0]\n",
    "etiquetas_entrenamiento_transformados_translacionX = etiquetas_entrenamiento\n",
    "#\n",
    "##Generar transformacion TRANSLACION EJE Y\n",
    "datos_entrenamiento_transformados_translacionY = desplazar_posesY(datos_entrenamiento[5],etiquetas_entrenamiento[5])[0]\n",
    "etiquetas_entrenamiento_transformados_translacionY = etiquetas_entrenamiento\n",
    "#\n",
    "##Generar transformacion FLIP\n",
    "datos_entrenamiento_transformados_flip = flip_poses(datos_entrenamiento[5],etiquetas_entrenamiento[5])[0]\n",
    "etiquetas_entrenamiento_transformados_flip = invertir_etiquetas(etiquetas_entrenamiento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0805bb-5030-4827-aac6-c8e56a1277af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformaciones dentro del rango recomendado: 91.78082191780823 %\n",
      "Transformaciones fuera del rango recomendado: 8.21917808219178 %\n",
      "Porcentaje total de puntos fuera de los límites del lienzo: 0.0 %\n",
      "número total de puntos analizados: 219000000\n"
     ]
    }
   ],
   "source": [
    "# ZOOM\n",
    "validacionZoom(datos_entrenamiento,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bfbdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformaciones dentro del rango recomendado: 97.94520547945206 %\n",
      "Transformaciones fuera del rango recomendado: 2.054794520547945 %\n"
     ]
    }
   ],
   "source": [
    "# TRANSLACION X\n",
    "validacionX(datos_entrenamiento,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c6074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformaciones dentro del rango recomendado: 99.31506849315068 %\n",
      "Transformaciones fuera del rango recomendado: 0.684931506849315 %\n"
     ]
    }
   ],
   "source": [
    "# TRANSLACION Y\n",
    "validacionX(datos_entrenamiento,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018737a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de transformaciones válidas: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# FLIP\n",
    "validacionFlip(datos_entrenamiento,etiquetas_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddeedd-1662-44af-8e5a-fd8efbd07071",
   "metadata": {},
   "source": [
    "# VER TENSORES TRANSFORMADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[38]), gif(datos_entrenamiento_transformados_zoom), \"resultadoZoom.gif\")\n",
    "\n",
    "Image(\"resultadoZoom.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b958b44-5574-49c9-b20f-03f9eb3ba3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos_entrenamiento[5])\n",
    "print((datos_entrenamiento[5])-(datos_entrenamiento_transformados_zoom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[5]), gif(datos_entrenamiento_transformados_translacionX), \"resultadoX.gif\")\n",
    "\n",
    "Image(\"resultadoX.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f5f8-f3d0-4abc-831d-4f1e5cd7a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[5]), gif(datos_entrenamiento_transformados_translacionY), \"resultadoY.gif\")\n",
    "\n",
    "Image(\"resultadoY.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gifComparaTransformado import *\n",
    "from generar_gif import *\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "unir_gifs(gif(datos_entrenamiento[5]), gif(datos_entrenamiento_transformados_flip), \"resultadoFlip.gif\")\n",
    "\n",
    "Image(\"resultadoFlip.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e45a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generar_gif import gif\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(gif(datos_entrenamiento_transformados_zoom[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimo_zoom = torch.min(datos_entrenamiento_transformados_zoom_normalized)\n",
    "minimo_flip = torch.min(datos_entrenamiento_transformados_flip_normalized)\n",
    "minimo_translacionY = torch.min(datos_entrenamiento_transformados_translacionY_normalized)\n",
    "minimo_original = torch.min(datos_entrenamiento_normalized)\n",
    "\n",
    "maximo_zoom = torch.max(datos_entrenamiento_transformados_zoom_normalized)\n",
    "maximo_flip = torch.max(datos_entrenamiento_transformados_flip_normalized)\n",
    "maximo_translacionY = torch.max(datos_entrenamiento_transformados_translacionY_normalized)\n",
    "maximo_original = torch.max(datos_entrenamiento_normalized)\n",
    "\n",
    "# Calcular los mínimos de cada tensor individualmente\n",
    "\n",
    "minimos = [minimo_zoom, minimo_flip, minimo_translacionY, minimo_original]\n",
    "\n",
    "# Encontrar el mínimo global iterativamente\n",
    "minimo_global = minimos[0]\n",
    "for minimo in minimos[1:]:\n",
    "    minimo_global = torch.min(minimo_global, minimo)\n",
    "\n",
    "# Imprimir el mínimo global\n",
    "print(\"Valor mínimo global:\", minimo_global)\n",
    "\n",
    "# Calcular los máximos de cada tensor individualmente\n",
    "maximos = [maximo_zoom, maximo_flip, maximo_translacionY, maximo_original]\n",
    "\n",
    "# Encontrar el máximo global iterativamente\n",
    "maximo_global = maximos[0]\n",
    "for maximo in maximos[1:]:\n",
    "    maximo_global = torch.max(maximo_global, maximo)\n",
    "\n",
    "# Imprimir el máximo global\n",
    "print(\"Valor máximo global:\", maximo_global)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2178ef-aba3-4dff-87a2-36618050d04c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VER LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595a92e-0e20-4e01-be23-867d58c3cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fino --port 6457"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc67fc-2518-43fd-8be5-5ec87d6afc82",
   "metadata": {},
   "source": [
    "# ENTRENAR OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe3f65-cedb-4ef8-bcfb-219bd3c1e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego, puedes utilizar los DataLoader en las funciones train_with_optuna y train_final_model\n",
    "from CustomDataset import *\n",
    "study = train_with_optuna(datos_entrenamiento, etiquetas_entrenamiento, datos_validacion, etiquetas_validacion, num_trials=100, num_epochs=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Luego, entrenamos el modelo final con los mejores parámetros encontrados por Optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ee201-5c58-4869-a110-eedccb30dcc5",
   "metadata": {},
   "source": [
    "# ENTRENAR FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b52c8-b2b1-4c4d-9995-66c1e7dabbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader = crear_dataloader(datos_entrenamiento, etiquetas_entrenamiento, datos_validacion, etiquetas_validacion, batch_size)\n",
    "\n",
    "model, accuracy = train_final_model(train_loader, val_loader, study, num_epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030f013-7b7f-409e-8880-94475748cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAR DATASET CON TRANSFORMACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb72e0c-b37d-4a32-999c-6e32b78dbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ENTRENAMIENTO INICIAL',datos_entrenamiento.shape[0])\n",
    "print('VALIDACION INICIAL',datos_validacion.shape[0])\n",
    "print('PRUEBA INICIAL',datos_prueba.shape[0])\n",
    "\n",
    "print('ENTRENAMIENTO INICIAL',datos_entrenamiento_trans.shape[0])\n",
    "print('VALIDACION INICIAL',datos_validacion_trans.shape[0])\n",
    "print('PRUEBA INICIAL',datos_prueba_trans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e34a38-5902-4dff-b6fb-0b6c7f66ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los datos de entrenamiento y validación\n",
    "datos_entrenamiento_final_total = torch.cat((datos_entrenamiento_trans, datos_validacion_trans), dim=0)\n",
    "etiquetas_entrenamiento_final_total = torch.cat((etiquetas_entrenamiento_trans, etiquetas_validacion_trans), dim=0)\n",
    "\n",
    "# Preparar los dataloaders con los datos combinados\n",
    "train_loader, val_loader = preparar_entrenamiento(datos_entrenamiento_final_total, etiquetas_entrenamiento_final_total, datos_prueba_trans, etiquetas_prueba_trans, 128)\n",
    "\n",
    "# Entrenamiento del modelo con los mejores parámetros\n",
    "#best_params = study.best_trial.params\n",
    "best_params_local = {'learning_rate': 2.23e-06, 'lstm_units': 1297, 'dense_units': 1206, 'dense_units0': 1274, \n",
    "                     'dropout_rate0': 0.3, 'dropout_rate1': 0.2, 'dropout_rate2': 0.2, \n",
    "                     'kernel_regularizer': None}\n",
    "modelo_final = entrenar_modelo(train_loader, val_loader, best_params_local, num_epochs=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09191772-c3ef-4715-8161-6325d9355ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
