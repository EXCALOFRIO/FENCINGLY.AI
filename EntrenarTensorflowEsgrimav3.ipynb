{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "eMPlyPkYs8rC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EXCALOFRIO/FENCINGLY.AI/blob/main/EntrenarTensorflowEsgrimav3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTS"
      ],
      "metadata": {
        "id": "1rMn0ofPnyqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0RjnkhhTfDES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48aa5973-23e4-427c-9cbd-5d37b9e18846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import shutil\n",
        "!apt install unrar\n",
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVPIzRNCniuK",
        "outputId": "a501efbd-1728-4f32-bc2b-9de227fd56b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 22 13:16:46 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "F6Fk2K2KffnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa721ab3-5d5b-4ef1-e318-8b3bbbdab58a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rarfile import RarFile\n",
        "\n",
        "# Ruta del archivo RAR\n",
        "ruta_rar = \"/content/drive/MyDrive/TFG/JSON_FORMADOS.rar\"\n",
        "\n",
        "# Ruta donde se desea descomprimir el archivo\n",
        "ruta_destino = \"/content/DATA_JSON/\"\n",
        "\n",
        "# Extraer el archivo RAR en la ruta especificada\n",
        "with RarFile(ruta_rar) as rar:\n",
        "  rar.extractall(ruta_destino)\n"
      ],
      "metadata": {
        "id": "DfdtqOC4fh_s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPARAR DATOS"
      ],
      "metadata": {
        "id": "DXupGF8PnpiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel(logging.ERROR)\n"
      ],
      "metadata": {
        "id": "-6h4u5VLfE3N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_datos(directorio, num_frames=100):\n",
        "    datos = []\n",
        "    for archivo_json in os.listdir(directorio):\n",
        "        ruta_json = os.path.join(directorio, archivo_json)\n",
        "        with open(ruta_json) as f:\n",
        "            datos_json = json.load(f)\n",
        "            secuencia = np.zeros((num_frames, 2, 75))  # Inicializar matriz para la secuencia\n",
        "            for i, frame in enumerate(datos_json['frames'][:num_frames]):\n",
        "                poses = frame['poses'][:2]  # Tomar solo las primeras 2 poses\n",
        "                for j, pose in enumerate(poses):\n",
        "                    keypoints = pose['pose_keypoints_2d'][:75]  # Tomar solo los primeros 75 keypoints\n",
        "                    secuencia[i, j, :] = keypoints\n",
        "            datos.append(secuencia)\n",
        "    return datos\n",
        "\n",
        "\n",
        "def dividir_datos(datos, porcentaje_entrenamiento):\n",
        "    cantidad_entrenamiento = int(porcentaje_entrenamiento * len(datos))\n",
        "    indices = np.random.permutation(len(datos))\n",
        "    datos_entrenamiento = [datos[i] for i in indices[:cantidad_entrenamiento]]\n",
        "    datos_prueba = [datos[i] for i in indices[cantidad_entrenamiento:]]\n",
        "    return datos_entrenamiento, datos_prueba\n",
        "\n",
        "# Directorios donde se encuentran los datos\n",
        "izquierda_dir = r\"/content/DATA_JSON/IZQUIERDA_NORMALIZADO\"\n",
        "derecha_dir = r\"/content/DATA_JSON/DERECHA_NORMALIZADO\"\n",
        "\n",
        "# Cargar los datos\n",
        "datos_izquierda = cargar_datos(izquierda_dir)\n",
        "datos_derecha = cargar_datos(derecha_dir)\n",
        "\n",
        "# Dividir datos en conjuntos de entrenamiento y prueba\n",
        "porcentaje_entrenamiento = 0.5\n",
        "datos_entrenamiento_izquierda, datos_prueba_izquierda = dividir_datos(datos_izquierda, porcentaje_entrenamiento)\n",
        "datos_entrenamiento_derecha, datos_prueba_derecha = dividir_datos(datos_derecha, porcentaje_entrenamiento)\n",
        "\n",
        "# Convertir a arrays numpy\n",
        "datos_entrenamiento_izquierda = np.array(datos_entrenamiento_izquierda)\n",
        "datos_entrenamiento_derecha = np.array(datos_entrenamiento_derecha)\n",
        "datos_prueba_izquierda = np.array(datos_prueba_izquierda)\n",
        "datos_prueba_derecha = np.array(datos_prueba_derecha)\n",
        "\n",
        "# Crear etiquetas para los datos de entrenamiento y prueba\n",
        "etiquetas_entrenamiento = np.concatenate((np.ones(len(datos_entrenamiento_izquierda)), np.zeros(len(datos_entrenamiento_derecha))))\n",
        "etiquetas_prueba = np.concatenate((np.ones(len(datos_prueba_izquierda)), np.zeros(len(datos_prueba_derecha))))\n",
        "\n",
        "# Mezclar los datos de entrenamiento y prueba\n",
        "datos_entrenamiento = np.concatenate((datos_entrenamiento_izquierda, datos_entrenamiento_derecha))\n",
        "datos_prueba = np.concatenate((datos_prueba_izquierda, datos_prueba_derecha))\n",
        "\n",
        "del datos_izquierda\n",
        "del datos_derecha\n",
        "del datos_entrenamiento_izquierda\n",
        "del datos_entrenamiento_derecha\n",
        "del datos_prueba_izquierda\n",
        "del datos_prueba_derecha"
      ],
      "metadata": {
        "id": "hETTx0N0ii9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la distribución de clases en los datos de entrenamiento y prueba\n",
        "def calcular_distribucion_clases(etiquetas):\n",
        "    clases, recuento = np.unique(etiquetas, return_counts=True)\n",
        "    distribucion = dict(zip(clases, recuento))\n",
        "    total_muestras = len(etiquetas)\n",
        "    for clase, count in distribucion.items():\n",
        "        porcentaje = (count / total_muestras) * 100\n",
        "        print(f\"Clase {clase}: {count} muestras ({porcentaje:.2f}%)\")\n",
        "\n",
        "# Calcular distribución de clases en los datos de entrenamiento\n",
        "print(\"Distribución de clases en datos de entrenamiento:\")\n",
        "calcular_distribucion_clases(etiquetas_entrenamiento)\n",
        "\n",
        "# Calcular distribución de clases en los datos de prueba\n",
        "print(\"\\nDistribución de clases en datos de prueba:\")\n",
        "calcular_distribucion_clases(etiquetas_prueba)\n",
        "\n",
        "print(f\"Número de muestras en datos de entrenamiento: {len(datos_entrenamiento)}\")\n",
        "print(f\"Número de muestras en datos de prueba: {len(datos_prueba)}\")\n",
        "\n",
        "print(datos_entrenamiento[25])\n"
      ],
      "metadata": {
        "id": "smNOXoY4kTAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELO"
      ],
      "metadata": {
        "id": "D2XfeIV_ndLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO ORIG"
      ],
      "metadata": {
        "id": "OCV1KqhJpIzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "# Definir el modelo\n",
        "def define_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=True, input_shape=(100, 150)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Crear el modelo\n",
        "model = define_model()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G4_906yjfImt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO PRUEBA"
      ],
      "metadata": {
        "id": "zRRYtB7VpFLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPILAR\n"
      ],
      "metadata": {
        "id": "a6sLPF1An-RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NcOMzqyRn8-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "e6Fl41jPnXsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORIG"
      ],
      "metadata": {
        "id": "EZ3I3CQ_s7Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your data generator function\n",
        "def generador_datos(datos, etiquetas, batch_size):\n",
        "    while True:\n",
        "        indices = np.arange(len(datos))\n",
        "        np.random.shuffle(indices)\n",
        "        for i in range(0, len(datos), batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_datos = [datos[j] for j in batch_indices]\n",
        "            # Aplanar los datos de las poses y eliminar las dimensiones de tamaño 1\n",
        "            batch_datos = np.array(batch_datos).reshape(-1, 100, 2*75)\n",
        "            batch_etiquetas = np.array([etiquetas[j] for j in batch_indices])\n",
        "            yield batch_datos, batch_etiquetas\n",
        "\n",
        "# Define your parameters\n",
        "batch_size = 5679  # Puedes ajustar esto según la memoria de tu máquina\n",
        "\n",
        "# Crear generadores para los datos de entrenamiento y prueba\n",
        "generador_entrenamiento = generador_datos(datos_entrenamiento, etiquetas_entrenamiento, batch_size)\n",
        "generador_prueba = generador_datos(datos_prueba, etiquetas_prueba, batch_size)\n"
      ],
      "metadata": {
        "id": "J764Pn6_7ih9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in generador_datos(datos_entrenamiento, etiquetas_entrenamiento, batch_size):\n",
        "    print(x.shape)  # Debe imprimir algo como (batch_size, 100, 150)\n",
        "    break"
      ],
      "metadata": {
        "id": "xHervPn0Awll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch=len(datos_entrenamiento) // batch_size\n",
        "print(steps_per_epoch)"
      ],
      "metadata": {
        "id": "D3L6sFgEHoTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "import datetime\n",
        "\n",
        "# Directorio de registro para TensorBoard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Directorio para guardar el modelo\n",
        "model_checkpoint_dir = \"saved_models/\"\n",
        "\n",
        "# Definir callbacks para el entrenamiento, como detención temprana, TensorBoard y ModelCheckpoint\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5000, verbose=1, mode='min'),\n",
        "    # Definir un ModelCheckpoint para guardar el modelo cada 100 épocas\n",
        "    ModelCheckpoint(model_checkpoint_dir + \"model_{epoch:02d}.h5\",\n",
        "                    save_best_only=False,  # No guardar solo el mejor modelo\n",
        "                    save_freq=200,  # Guardar cada 100 épocas\n",
        "                    verbose=1),\n",
        "    tensorboard_callback\n",
        "]\n",
        "\n",
        "# Iniciar el entrenamiento con los callbacks definidos\n",
        "history = model.fit(\n",
        "    generador_entrenamiento,\n",
        "    steps_per_epoch=len(datos_entrenamiento) // batch_size,\n",
        "    epochs=100000,  # Número de épocas a entrenar\n",
        "    validation_data=generador_prueba,\n",
        "    validation_steps=len(datos_prueba) // batch_size,\n",
        "    callbacks=callbacks  # Incluir todos los callbacks necesarios\n",
        ")\n"
      ],
      "metadata": {
        "id": "mwKLDtVq-toI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datos_entrenamiento) // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDZku2krEhsS",
        "outputId": "7ef16126-0f17-4a47-bce5-f855f83ad2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V2"
      ],
      "metadata": {
        "id": "eMPlyPkYs8rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "import datetime\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class SaveModelEveryNthEpoch(Callback):\n",
        "    def __init__(self, filepath, save_every_n_epochs):\n",
        "        super(SaveModelEveryNthEpoch, self).__init__()\n",
        "        self.filepath = filepath\n",
        "        self.save_every_n_epochs = save_every_n_epochs\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.save_every_n_epochs == 0:\n",
        "            filepath = self.filepath.format(epoch=epoch + 1)\n",
        "            self.model.save(filepath)\n",
        "            print(f\"Model saved at epoch {epoch + 1}.\")\n",
        "\n",
        "# Directorio de registro para TensorBoard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "# Directorio para guardar el modelo\n",
        "model_checkpoint_dir = \"saved_models2/\"\n",
        "model_checkpoint_path = model_checkpoint_dir + \"model_{epoch:02d}.h5\"\n",
        "\n",
        "# Definir callbacks para el entrenamiento, incluyendo la nueva función de callback personalizada\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5000, verbose=1, mode='min'),\n",
        "    SaveModelEveryNthEpoch(filepath=model_checkpoint_path, save_every_n_epochs=100),\n",
        "    tensorboard_callback\n",
        "]\n",
        "\n",
        "\n",
        "# Iniciar el entrenamiento con los callbacks definidos\n",
        "history = model.fit(\n",
        "    generador_entrenamiento,\n",
        "    steps_per_epoch=len(datos_entrenamiento) // batch_size,\n",
        "    epochs=100000,  # Número de épocas a entrenar\n",
        "    validation_data=generador_prueba,\n",
        "    validation_steps=len(datos_prueba) // batch_size,\n",
        "    callbacks=callbacks  # Incluir todos los callbacks necesarios\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "pBR4srRC93Gh",
        "outputId": "0938eee6-71aa-426f-af82-bf15332b9677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4994"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8e5b978cffa2>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Iniciar el entrenamiento con los callbacks definidos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mgenerador_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos_entrenamiento\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0;34m\"Unexpected value for `steps_per_epoch`. Received value is 0. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0;34m\"Please check the docstring for `model.fit()` for supported \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar modelo"
      ],
      "metadata": {
        "id": "XBtZxNHapgOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo\n",
        "model.save(\"modelo_esgrima_v2.h5\")"
      ],
      "metadata": {
        "id": "OIWVKOtEpe1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descargar"
      ],
      "metadata": {
        "id": "sJ5fir9nY-V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "zip -r modelo_esgrima_v2.zip modelo_esgrima_v2.h5\n",
        "nombre_archivo = \"modelo_esgrima_v2.zip\"\n",
        "\n",
        "files.download(nombre_archivo)"
      ],
      "metadata": {
        "id": "2Jwvih4JYs4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "zip -r modelo_esgrima_v2.zip modelo_esgrima_v2.h5\n",
        "nombre_archivo = \"modelo_esgrima_v2.zip\"\n",
        "\n",
        "files.download(nombre_archivo)"
      ],
      "metadata": {
        "id": "3EahMdgPPZlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Carpeta que deseas comprimir\n",
        "folder_to_zip = '/content/saved_models'\n",
        "\n",
        "# Nombre del archivo zip que deseas crear\n",
        "zip_filename = '/content/saved_models'\n",
        "\n",
        "# Comprimir la carpeta en un archivo zip\n",
        "shutil.make_archive(zip_filename, 'zip', folder_to_zip)\n",
        "\n",
        "# Descargar el archivo zip\n",
        "from google.colab import files\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MrF7zFEJXXrg",
        "outputId": "a15d9277-438b-4cc3-b32e-7fdcf24cfd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_594ed27e-176f-46de-a6bf-c3416e5d6d83\", \"saved_models\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TENSORBOARD"
      ],
      "metadata": {
        "id": "R0JWVwzdntbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "metadata": {
        "id": "cebCHzzDkSY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}